{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_url(doi, base_url):\n",
    "    url = f\"{base_url}/{doi}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Trouver le lien direct du PDF\n",
    "        iframe = soup.find(\"iframe\", id=\"pdf\")\n",
    "        if iframe:\n",
    "            pdf_path = iframe.get(\"src\")\n",
    "            if pdf_path:\n",
    "                return urllib.parse.urljoin(base_url, pdf_path)\n",
    "\n",
    "        # Alternative pour les nouvelles versions de Sci-Hub\n",
    "        button = soup.find(\"button\", onclick=lambda x: x and \"location.href\" in x)\n",
    "        if button:\n",
    "            js_code = button[\"onclick\"]\n",
    "            pdf_path = js_code.split(\"=\")[1].strip(\"';\")\n",
    "            return urllib.parse.urljoin(base_url, pdf_path)\n",
    "\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'accès à {base_url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def download_pdf(pdf_url, filename, folder_path):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        response = requests.get(pdf_url, headers=headers, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Create the folder if it doesn't exist\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        # Create the file in the folder\n",
    "        with open(os.path.join(folder_path, filename), \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du téléchargement: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "def get_doi_from_doi_url(doi_url):\n",
    "    # Get the DOI from the url \"https://doi.org/10.1149/1.2069372\" -> \"10.1149/1.2069372\"\n",
    "    doi = doi_url.split(\"https://doi.org/\")[1]\n",
    "    return doi\n",
    "\n",
    "\n",
    "def get_pdf_from_doi_url(doi_url, folder_path, ID):\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python scihub_downloader.py <DOI>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    scihub_domains = [\n",
    "        # \"https://sci-hub.se\",\n",
    "        # \"https://sci-hub.st\",\n",
    "        # \"https://sci-hub.ru\",\n",
    "        \"https://sci-hub.ee\",\n",
    "    ]\n",
    "\n",
    "    pdf_url = None\n",
    "    for domain in scihub_domains:\n",
    "        print(f\"Essai avec le domaine: {domain}\")\n",
    "        doi = get_doi_from_doi_url(doi_url)\n",
    "        pdf_url = get_pdf_url(doi, domain)\n",
    "        if pdf_url:\n",
    "            print(f\"PDF trouvé sur {domain}\")\n",
    "            break\n",
    "\n",
    "    if not pdf_url:\n",
    "        print(\"Échec de la localisation du PDF sur tous les domaines Sci-Hub\")\n",
    "        return\n",
    "    filename = ID + \".pdf\"\n",
    "    folder_path = \"pdfs\"\n",
    "    print(f\"Tentative de téléchargement depuis: {pdf_url}\")\n",
    "\n",
    "    if download_pdf(pdf_url, filename, folder_path):\n",
    "        print(f\"PDF sauvegardé avec succès sous: {filename}\")\n",
    "    else:\n",
    "        print(\"Échec du téléchargement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open sheet_with_doi_clean.csv\n",
    "df = pd.read_csv(\n",
    "    \"sheet_with_doi_clean.csv\",\n",
    "    sep=\";\",  # Spécifier explicitement le délimiteur\n",
    "    engine=\"python\",\n",
    "    quotechar='\"'\n",
    ")\n",
    "# Add a column with the DOI\n",
    "for index, row in df.iterrows():\n",
    "    # Check if pdf is already download\n",
    "    if os.path.exists(f\"pdfs/{row['ID']}.pdf\"):\n",
    "        print(f\"PDF déjà téléchargé pour {row['Reference']}\")\n",
    "        continue\n",
    "    \n",
    "    # Download PDF\n",
    "    print(f\"Téléchargement du PDF pour {row['Reference']}\")\n",
    "    get_pdf_from_doi_url(row['DOI'], \"pdfs\", row['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wich pdf is not downloaded\n",
    "cpt = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if not os.path.exists(f\"pdfs/{row['ID']}.pdf\"):\n",
    "        print(f\"PDF non téléchargé pour {row['ID']} - {row['Reference']}\")\n",
    "        cpt += 1\n",
    "        \n",
    "print(f'{cpt} pdfs aren''t downloaded')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
